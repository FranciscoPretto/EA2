{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EA3_Pretto_Francisco_41765899_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42YK66ZCdE7L"
      },
      "source": [
        "# 1. Introducción\n",
        "\n",
        "El siguiente cuaderno realiza la conversion de valores de temperatura en Celsius a Fahrenheit o viceversa. Se pretende simular un gran conjunto de lecturas que se almacenan en un vector. Se simulan las lecturas con valores seudoaleatorios a los cuales les podemos definir un techo y piso por parametros como asi la cantidad de estos. Las formulas de conversión son las siguientes:\n",
        "\n",
        "De Celsius a Farenheit:  <center> $F$°= ( $C$° * 9/5 ) + 32 </center>\n",
        "\n",
        "De Farenheit a Celsius:  <center> $C$°= ( $F$° + 32 ) * 5/9 </center>\n",
        "\n",
        "El objetivo es realizar la conversion de manera más rápida utilizando el paralelismo que nos da CUDA, en este caso trabajando con una sola dimensión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSCqd4CkdYxb"
      },
      "source": [
        "# 2. Armado del ambiente\n",
        "\n",
        "*   Se instala el módulo de CUDA en el cuaderno.\n",
        "*  Se importan las bibliotecas Necesarias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GOTns6LrpNP"
      },
      "source": [
        "!pip install pycuda\n",
        "\n",
        "from datetime import datetime\n",
        "import random\n",
        "import numpy\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoBZ12NmdfEd"
      },
      "source": [
        "# 3. Desarrollo\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYIjYTv3nzxC"
      },
      "source": [
        "## 3.1 Ejecucion Secuencial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAl22L-8hMaF",
        "outputId": "d69be7fc-2b5d-4656-af77-eeb8bdf6fd10"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_lecturas =   500000#@param {type: \"number\"}\n",
        "conversor = \"Grado Fahrenheit a Grado Celsius\" #@param [\"Grado Fahrenheit a Grado Celsius\", \"Grado Celsius a Grado Fahrenheit\"]\n",
        "temp_min =  -100 #@param {type:\"slider\", min:-100, max:0, step:1}\n",
        "temp_max = 1000  #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "# --------------------------------------------\n",
        "\n",
        "tiempo_total_secuencial = datetime.now()\n",
        "\n",
        "#Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "#Simplifico la direccion de conversion\n",
        "\n",
        "if(conversor==\"Grado Celsius a Grado Fahrenheit\"):\n",
        "  direccion_conversion=1\n",
        "else:\n",
        "  direccion_conversion=0\n",
        "\n",
        "# Genero la lista con las lecturas\n",
        "temperaturas = []\n",
        "for i in range(0,cantidad_lecturas):\n",
        "  temperaturas+=[round(random.uniform(temp_min, temp_max),2)]\n",
        "\n",
        "#Realizo el calculo\n",
        "\n",
        "tiempo_cpu = datetime.now()\n",
        "\n",
        "temperaturas_resultado=[]\n",
        "\n",
        "for i in range(0,cantidad_lecturas-1):\n",
        "  if(direccion_conversion==1):\n",
        "    temperaturas_resultado+= [(temperaturas[i] * 9/5)+32]\n",
        "  else:\n",
        "    temperaturas_resultado+= [(temperaturas[i] + 32)*5/9]\n",
        "\n",
        "tiempo_cpu = datetime.now() - tiempo_cpu\n",
        "tiempo_total_secuencial = datetime.now() - tiempo_total_secuencial\n",
        "print( \"Cantidad de elementos: \", cantidad_lecturas )\n",
        "print(\"Tiempo Total: \", tiempo_en_ms( tiempo_total_secuencial ), \"[ms]\" )\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_cpu   ), \"[ms]\" )\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad de elementos:  500000\n",
            "Tiempo Total:  590.145 [ms]\n",
            "Tiempo CPU:  140.297 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zw09GXXhOHM"
      },
      "source": [
        "##3.2 Ejecución paralela con CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-5JkeLNroTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a14070-d947-431d-cc0b-bd7752e92ab5"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.2.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_lecturas =   500000#@param {type: \"number\"}\n",
        "conversor = \"Grado Fahrenheit a Grado Celsius\" #@param [\"Grado Fahrenheit a Grado Celsius\", \"Grado Celsius a Grado Fahrenheit\"]\n",
        "temp_min =  -100 #@param {type:\"slider\", min:-100, max:0, step:1}\n",
        "temp_max = 1000  #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "# --------------------------------------------\n",
        "\n",
        "#CPU - Tomo el tiempo inicial total\n",
        "tiempo_total_cuda = datetime.now()\n",
        "\n",
        "#Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "#CPU - Simplifico la direccion de conversion\n",
        "\n",
        "if(conversor==\"Grado Celsius a Grado Fahrenheit\"):\n",
        "  direccion_conversion=1\n",
        "else:\n",
        "  direccion_conversion=0\n",
        "\n",
        "# CPU - Genero las lecturas\n",
        "temperaturas = []\n",
        "for i in range(0,cantidad_lecturas):\n",
        "  temperaturas+=[round(random.uniform(temp_min, temp_max),2)]\n",
        "\n",
        "# CPU - Defino la memoria de los vectores en cpu.\n",
        "temperaturas_cpu = numpy.asarray(temperaturas)\n",
        "temperaturas_cpu = temperaturas_cpu.astype( numpy.float32() )\n",
        "temperaturas_resultado_cpu = numpy.empty_like(temperaturas_cpu)\n",
        "\n",
        "# GPU - reservo la memoria GPU.\n",
        "temperaturas_gpu = cuda.mem_alloc(temperaturas_cpu.nbytes)\n",
        "temperaturas_resultado_gpu = cuda.mem_alloc( temperaturas_resultado_cpu.nbytes )\n",
        "\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod( temperaturas_gpu, temperaturas_cpu )\n",
        "\n",
        "# CPU - Defino la función kernel que ejecutará en GPU.\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void conversor_temperatura( int n, int direccion_conversion, float *temp_original, float *temp_resultado )\n",
        "{\n",
        "  #define CONST1 9/5\n",
        "  #define CONST2 5/9\n",
        "  #define CONST3 32\n",
        "\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  if( idx < n )\n",
        "  {\n",
        "    if(direccion_conversion==1)\n",
        "    { \n",
        "      temp_resultado[idx] = (temp_original[idx] *CONST1)+CONST3;\n",
        "    }else{\n",
        "      temp_resultado[idx] = (temp_original[idx]-CONST3)*CONST2;\n",
        "    }\n",
        "   \n",
        "  }\n",
        "}\n",
        "\"\"\") \n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"conversor_temperatura\")\n",
        "\n",
        "#CPU - Tomo el tiempo inicial de ejecución de la función kernel.\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "# GPU - Ejecuta el kernel.\n",
        "dim_hilo = 256\n",
        "dim_bloque = numpy.int( (cantidad_lecturas+dim_hilo-1) / dim_hilo )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "\n",
        "kernel( numpy.int32(cantidad_lecturas),numpy.int32(direccion_conversion), temperaturas_gpu, temperaturas_resultado_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "\n",
        "#CPU - Tomo el tiempo final de ejecución de la función kernel.\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# CPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh( temperaturas_resultado_cpu, temperaturas_resultado_gpu )\n",
        "\n",
        "#CPU- Tomo el tiempo total final.\n",
        "tiempo_total_cuda = datetime.now() - tiempo_total_cuda\n",
        "\n",
        "#CPU - Informo los resultados.\n",
        "print( \"Cantidad de elementos: \", cantidad_lecturas )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "print(\"Tiempo Total: \", tiempo_en_ms( tiempo_total_cuda ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread x:  256 , Bloque x: 1954\n",
            "Cantidad de elementos:  500000\n",
            "Thread x:  256 , Bloque x: 1954\n",
            "Tiempo Total:  479.194 [ms]\n",
            "Tiempo GPU:  1.146 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on4yRLANdx4W"
      },
      "source": [
        "# 4. Tabla de pasos\n",
        "\n",
        "> Se define la tabla de pasos del punto 3.2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Procesador | Función | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de paramtros desde Colab.\n",
        "CPU      |  direccion_conversion= | Simplifico la direccion de conversion\n",
        "CPU      | temperaturas+=[round(random.uniform(temp_min, temp_max),2)] | Genero las lecturas\n",
        "CPU      | numpy.asarray() | Defino la memoria de los vectores en cpu\n",
        "GPU      | cuda.mem_alloc()| Reservo la memoria GPU\n",
        "GPU      | cuda.memcpy_htod() | Copio la memoria al GPU\n",
        "CPU      | SourceModule()| Defino la función kernel que ejecutará en GPU\n",
        "CPU      | module.get_function()| Genero la función kernel\n",
        "CPU      | dim_tx/dim_bx | Calcula las dimensiones.\n",
        "GPU      | kernel()| Ejecuta el kernel\n",
        "CPU      | cuda.memcpy_dtoh()| Copio el resultado desde la memoria GPU\n",
        "CPU      | print()| Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8e56_d5d453"
      },
      "source": [
        "# 5. Conclusiones\n",
        "\n",
        "Habiendo ejecutado varias veces el ejercicio con una cantidad de elementos igual a 500000 se puede apreciar que cuando no se utiliza CUDA, se tarda un 30% mas en ejecutar. Lo interesante es que si tomamos solo el tiempo en que se ejecuta la funcion paralela podemos apreciar que se ejecuta mas de 350 veces mas rápido. Esto sucede debido a la preparación por el lado del CPU que conlleva ejecutar estas tareas en CUDA desde pyton, ya sea preparar datos para que sean compatibles como generar el codigo fuente o pasar informacion entre ambas memorias.\n",
        "\n",
        "Definitivamente para grandes volumenes de datos la ejecución paralela hace lo imposible posible pero si nuestra cantidad de datos no es lo suficientemente grande, todo lo que conlleva ejecutar en CUDA no vale la pena.\n",
        "\n",
        "Para esta conclusión se ejecutaron 10 veces los ejercicios teniendo como resultados promedios:\n",
        "\n",
        "CPU - 3.1:\n",
        "\n",
        "*   Tiempo Total:  597.601 [ms]\n",
        "*   Tiempo CPU:  134.583 [ms]\n",
        "\n",
        "GPU - 3.2:\n",
        "\n",
        "*   Tiempo Total:  456.59 [ms]\n",
        "*   Tiempo GPU:  0.382 [ms]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqtxQznhd-JU"
      },
      "source": [
        "#6. Bibliografía\n",
        "\n",
        "Se utilizaron las bibliografías otorgadas por la catedra junto con:\n",
        "\n",
        "* https://www.digikey.com/es/resources/conversion-calculators/conversion-calculator-temperature\n",
        "*  https://j2logo.com/python/generar-numeros-aleatorios-en-python/\n",
        "*  https://www.mclibre.org/consultar/python/lecciones/python-listas.html\n",
        "\n"
      ]
    }
  ]
}