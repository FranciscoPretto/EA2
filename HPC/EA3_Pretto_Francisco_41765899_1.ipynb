{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de EA3_Pretto_Francisco_41765899_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42YK66ZCdE7L"
      },
      "source": [
        "# 1. Introducción\n",
        "\n",
        "El siguiente cuaderno realiza la conversion de valores de temperatura en Celsius a Fahrenheit o viceversa. Se pretende simular un gran conjunto de lecturas que se almacenan en un vector. Se simulan las lecturas con valores seudoaleatorios a los cuales les podemos definir un techo y piso por parametros como asi la cantidad de estos. Las formulas de conversión son las siguientes:\n",
        "\n",
        "De Celsius a Farenheit:  <center> $F$°= ( $C$° * 9/5 ) + 32 </center>\n",
        "\n",
        "De Farenheit a Celsius:  <center> $C$°= ( $F$° + 32 ) * 5/9 </center>\n",
        "\n",
        "El objetivo es realizar la conversion de manera más rápida utilizando el paralelismo que nos da CUDA, en este caso trabajando con una sola dimensión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSCqd4CkdYxb"
      },
      "source": [
        "# 2. Armado del ambiente\n",
        "\n",
        "*   Se instala el módulo de CUDA en el cuaderno.\n",
        "*  Se importan las bibliotecas Necesarias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GOTns6LrpNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1104f6b8-63dc-4bf1-b194-0890085c1f4d"
      },
      "source": [
        "!pip install pycuda\n",
        "\n",
        "from datetime import datetime\n",
        "import random\n",
        "import numpy\n",
        "import math\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.6/dist-packages (2020.1)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.6/dist-packages (from pycuda) (2020.4.3)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7; python_version <= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoBZ12NmdfEd"
      },
      "source": [
        "# 3. Desarrollo\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYIjYTv3nzxC"
      },
      "source": [
        "## 3.1 Ejecucion Secuencial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAl22L-8hMaF",
        "outputId": "751b214f-08bd-4448-dc16-17bf0f26bac6"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_lecturas =   500000#@param {type: \"number\"}\n",
        "if(cantidad_lecturas<1):\n",
        "  raise Exception(\"El numero de lecturas debe ser mayor a 0\")\n",
        "cantidad_lecturas=math.trunc(cantidad_lecturas)\n",
        "conversor = \"Grado Fahrenheit a Grado Celsius\" #@param [\"Grado Fahrenheit a Grado Celsius\", \"Grado Celsius a Grado Fahrenheit\"]\n",
        "temp_min =  -100 #@param {type:\"slider\", min:-100, max:0, step:1}\n",
        "temp_max = 1000  #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "# --------------------------------------------\n",
        "\n",
        "tiempo_total_secuencial = datetime.now()\n",
        "\n",
        "#Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "#Simplifico la direccion de conversion\n",
        "\n",
        "if(conversor==\"Grado Celsius a Grado Fahrenheit\"):\n",
        "  direccion_conversion=1\n",
        "else:\n",
        "  direccion_conversion=0\n",
        "\n",
        "# Genero la lista con las lecturas\n",
        "temperaturas = []\n",
        "for i in range(0,cantidad_lecturas):\n",
        "  temperaturas+=[round(random.uniform(temp_min, temp_max),2)]\n",
        "\n",
        "#Realizo el calculo\n",
        "\n",
        "tiempo_cpu = datetime.now()\n",
        "\n",
        "temperaturas_resultado=[]\n",
        "\n",
        "for i in range(0,cantidad_lecturas-1):\n",
        "  if(direccion_conversion==1):\n",
        "    temperaturas_resultado+= [(temperaturas[i] * 9/5)+32]\n",
        "  else:\n",
        "    temperaturas_resultado+= [(temperaturas[i] + 32)*5/9]\n",
        "\n",
        "tiempo_cpu = datetime.now() - tiempo_cpu\n",
        "tiempo_total_secuencial = datetime.now() - tiempo_total_secuencial\n",
        "print( \"Cantidad de elementos: \", cantidad_lecturas )\n",
        "print(\"Tiempo Total: \", tiempo_en_ms( tiempo_total_secuencial ), \"[ms]\" )\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_cpu   ), \"[ms]\" )\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad de elementos:  500000\n",
            "Tiempo Total:  614.227 [ms]\n",
            "Tiempo CPU:  142.55 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zw09GXXhOHM"
      },
      "source": [
        "##3.2 Ejecución paralela con CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-5JkeLNroTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2e0025-a5b8-40c6-dd4a-b017a62922ef"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.2.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "\n",
        "cantidad_lecturas =  500000#@param {type:\"integer\"}\n",
        "if(cantidad_lecturas<1):\n",
        "  raise Exception(\"El numero de lecturas debe ser mayor a 0\")\n",
        "cantidad_lecturas=math.trunc(cantidad_lecturas)\n",
        "\n",
        "\n",
        "\n",
        "conversor = \"Grado Fahrenheit a Grado Celsius\" #@param [\"Grado Fahrenheit a Grado Celsius\", \"Grado Celsius a Grado Fahrenheit\"]\n",
        "temp_min =  -84 #@param {type:\"slider\", min:-100, max:0, step:1}\n",
        "temp_max = 80  #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "# --------------------------------------------\n",
        "\n",
        "#CPU - Tomo el tiempo inicial total\n",
        "tiempo_total_cuda = datetime.now()\n",
        "\n",
        "#Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "#CPU - Simplifico la direccion de conversion\n",
        "\n",
        "if(conversor==\"Grado Celsius a Grado Fahrenheit\"):\n",
        "  direccion_conversion=1\n",
        "else:\n",
        "  direccion_conversion=0\n",
        "\n",
        "# CPU - Genero las lecturas\n",
        "temperaturas = []\n",
        "for i in range(0,cantidad_lecturas):\n",
        "  temperaturas+=[round(random.uniform(temp_min, temp_max),2)]\n",
        "\n",
        "# CPU - Defino la memoria de los vectores en cpu.\n",
        "temperaturas_cpu = numpy.asarray(temperaturas)\n",
        "temperaturas_cpu = temperaturas_cpu.astype( numpy.float32() )\n",
        "temperaturas_resultado_cpu = numpy.empty_like(temperaturas_cpu)\n",
        "\n",
        "# GPU - reservo la memoria GPU.\n",
        "temperaturas_gpu = cuda.mem_alloc(temperaturas_cpu.nbytes)\n",
        "temperaturas_resultado_gpu = cuda.mem_alloc( temperaturas_resultado_cpu.nbytes )\n",
        "\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod( temperaturas_gpu, temperaturas_cpu )\n",
        "\n",
        "# CPU - Defino la función kernel que ejecutará en GPU.\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void conversor_temperatura( int n, int direccion_conversion, float *temp_original, float *temp_resultado )\n",
        "{\n",
        "  #define CONST1 9/5\n",
        "  #define CONST2 5/9\n",
        "  #define CONST3 32\n",
        "\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  if( idx < n )\n",
        "  {\n",
        "    if(direccion_conversion==1)\n",
        "    { \n",
        "      temp_resultado[idx] = (temp_original[idx] *CONST1)+CONST3;\n",
        "    }else{\n",
        "      temp_resultado[idx] = (temp_original[idx]-CONST3)*CONST2;\n",
        "    }\n",
        "   \n",
        "  }\n",
        "}\n",
        "\"\"\") \n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"conversor_temperatura\")\n",
        "\n",
        "#CPU - Tomo el tiempo inicial de ejecución de la función kernel.\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "# GPU - Ejecuta el kernel.\n",
        "dim_hilo = 256\n",
        "dim_bloque = numpy.int( (cantidad_lecturas+dim_hilo-1) / dim_hilo )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "\n",
        "kernel( numpy.int32(cantidad_lecturas),numpy.int32(direccion_conversion), temperaturas_gpu, temperaturas_resultado_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "\n",
        "#CPU - Tomo el tiempo final de ejecución de la función kernel.\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# CPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh( temperaturas_resultado_cpu, temperaturas_resultado_gpu )\n",
        "\n",
        "#CPU- Tomo el tiempo total final.\n",
        "tiempo_total_cuda = datetime.now() - tiempo_total_cuda\n",
        "\n",
        "#CPU - Informo los resultados.\n",
        "print( \"Cantidad de elementos: \", cantidad_lecturas )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "print(\"Tiempo Total: \", tiempo_en_ms( tiempo_total_cuda ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread x:  256 , Bloque x: 1954\n",
            "Cantidad de elementos:  500000\n",
            "Thread x:  256 , Bloque x: 1954\n",
            "Tiempo Total:  484.576 [ms]\n",
            "Tiempo GPU:  0.808 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on4yRLANdx4W"
      },
      "source": [
        "# 4. Tabla de pasos\n",
        "\n",
        "> Se define la tabla de pasos del punto 3.2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Procesador | Función | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de paramtros desde Colab.\n",
        "CPU      |  direccion_conversion= | Simplifico la direccion de conversion\n",
        "CPU      | temperaturas+=[round(random.uniform(temp_min, temp_max),2)] | Genero las lecturas\n",
        "CPU      | numpy.asarray() | Defino la memoria de los vectores en cpu\n",
        "GPU      | cuda.mem_alloc()| Reservo la memoria GPU\n",
        "GPU      | cuda.memcpy_htod() | Copio la memoria al GPU\n",
        "CPU      | SourceModule()| Defino la función kernel que ejecutará en GPU\n",
        "CPU      | module.get_function()| Genero la función kernel\n",
        "CPU      | dim_tx/dim_bx | Calcula las dimensiones.\n",
        "GPU      | kernel()| Ejecuta el kernel\n",
        "CPU      | cuda.memcpy_dtoh()| Copio el resultado desde la memoria GPU\n",
        "CPU      | print()| Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8e56_d5d453"
      },
      "source": [
        "# 5. Conclusiones\n",
        "\n",
        "Habiendo ejecutado varias veces el ejercicio con una cantidad de elementos igual a 500000 se puede apreciar que cuando no se utiliza CUDA, se tarda un 30% mas en ejecutar. Lo interesante es que si tomamos solo el tiempo en que se ejecuta la funcion paralela podemos apreciar que se ejecuta mas de 350 veces mas rápido. Esto sucede debido a la preparación por el lado del CPU que conlleva ejecutar estas tareas en CUDA desde pyton, ya sea preparar datos para que sean compatibles como generar el codigo fuente o pasar informacion entre ambas memorias.\n",
        "\n",
        "Definitivamente para grandes volumenes de datos la ejecución paralela hace lo imposible posible pero si nuestra cantidad de datos no es lo suficientemente grande, todo lo que conlleva ejecutar en CUDA no vale la pena.\n",
        "\n",
        "Para esta conclusión se ejecutaron 10 veces los ejercicios teniendo como resultados promedios:\n",
        "\n",
        "CPU - 3.1:\n",
        "\n",
        "*   Tiempo Total:  597.601 [ms]\n",
        "*   Tiempo CPU:  134.583 [ms]\n",
        "\n",
        "GPU - 3.2:\n",
        "\n",
        "*   Tiempo Total:  456.59 [ms]\n",
        "*   Tiempo GPU:  0.382 [ms]\n",
        "\n",
        "Se pueden ver como puntos importantes la generación de lecturas ( que se simula con la función random.uniform) y la aplicación de la formula lineal, ya sea en la ejecución secuencial mediante el \"for\" y en CUDA utilizando una dimensión. A pesar de ser un algoritmo sensillo, la mejora obtenida es inmensa y mientras mas cantidad de datos, mejor va a ser la relación. Este ejercicio me saco el \"prejuicio\" de que un procesador grafíco se debe utilizar solo para calculos complejos ya que, la aplicación en este caso esta totalmente justificada y trae una mejora real y tangible siendo muy facil de implementar.\n",
        "\n",
        "Al ejercicio se podria completar con la generación de numeros aleatorios mediante CUDA tambien, asi reduciendo la antes mencionada \"preparación por el lado del CPU\" ( tener en cuenta que en la vida real, esos datos se importan y no generan). Teniendo en cuenta la ultima aclaración, tambien se podria agregar una funcionalidad que lea las lecturas de un archivo (csv por ejemplo) y haga los calculos con esta.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqtxQznhd-JU"
      },
      "source": [
        "#6. Bibliografía\n",
        "\n",
        "Se utilizaron las bibliografías otorgadas por la catedra junto con:\n",
        "\n",
        "* https://www.digikey.com/es/resources/conversion-calculators/conversion-calculator-temperature\n",
        "*  https://j2logo.com/python/generar-numeros-aleatorios-en-python/\n",
        "*  https://www.mclibre.org/consultar/python/lecciones/python-listas.html\n",
        "\n"
      ]
    }
  ]
}