1.1 Motivación

El procesamiento paralelo es un tipo de procesamiento de la información, que permiteque se ejecuten varios procesos concurrentemente [5, 10, 17, 30, 35]. El procesamientoparalelo puede ser de diferentes tipos: i) Un tipo es ejecutar procesos independientessimultáneamente, los cuales son controlados por el sistema operativo (usando tiempocompartido, multiprogramación y multiprocesamiento). ii) Otro tipo es descomponer losprogramas en tareas (controladas por el sistema operativo, los compiladores, loslenguajes de programación, etc.), algunas de las cuales pueden ser ejecutadas en paralelo.iii) Finalmente, el último tipo se basa en usar técnicas de encauzamiento para introducirparalelismo a nivel de instrucciones, lo que implica dividirlas en pasos sucesivos quepueden ser ejecutados en paralelo, cada uno procesando datos diferentes.Es difícil determinar qué resulta más natural, sí el procesamiento paralelo o elsecuencial. Los enfoques paralelos resultan una necesidad, dada la constante afirmaciónde que la velocidad máxima en procesamiento secuencial se alcanzará prontamente,excepto que aparezcan avances en otras áreas que definan nuevos mecanismos deprocesamiento, los cuales pueden venir de nuevos descubrimientos en áreas tales comocomputación AND, computación cuántica, etc. En los últimos años, el uso extensivo delparalelismo ha estado ligada a varios hechos [2, 10, 13, 20]:

- La necesidad de mayor potencia de cálculo: independientemente de que la potenciade los procesadores aumente, siempre habrá un limite que dependerá de la tecnologíadel momento. Para aumentar la potencia de cálculo, además de los progresostecnológicos que permitan aumentar la velocidad de cálculo, se requieren nuevosparadigmas basados en cálculo paralelo. Es decir, una manera de aumentar lavelocidad de cálculo es usar múltiples procesadores juntos. Así, un problema esdividido en partes, cada una de las cuales es ejecutada en paralelo en diferentesprocesadores. La programación para esta forma de cálculo es conocida comoprogramación paralela, y las plataformas computacionales donde pueden serejecutadas estas aplicaciones son los sistemas paralelos y distribuidos. La idea que seusa es que al tener n computadores se debería tener n veces más poder de cálculo, loque conllevaría a que el problema pudiera resolverse en 1/n veces del tiemporequerido por el secuencial. Por supuesto, esto bajo condiciones ideales queraramente se consiguen en la práctica. Sin embargo, mejoras sustanciales pueden seralcanzadas dependiendo del problema y la cantidad de paralelismo presente en elmismo.

- Una mejor relación costo/rendimiento: en el orden económico, es muy importantetener máquinas con excelente relación costo/rendimiento. Normalmente, el mayorpoder de cálculo genera una explosión de costos que a veces lo hacen prohibitivo.Una manera para lograr mayor poder de cálculo sin costos excesivos es hacercooperar muchos elementos de cálculo de bajo poder, y por consiguiente, de bajoscostos.

- Potencia expresiva de los modelos de procesamiento paralelo: muchos problemasson más fáciles de modelar usando paradigmas paralelos, ya sea por la estructura quese usa para su resolución o porque el problema es intrínsecamente paralelo. Es decir,si desde el principio se puede pensar en los mecanismos paralelos/concurrentes pararesolver un problema, eso puede facilitar la implantación del modelo computacional.Esto podría permitir obtener mejores soluciones para los problemas a resolver, entiempos razonables de ejecución. Así, este enfoque permite el surguimiento demodelos de cálculos diferentes, a los modelos secuenciales. En pocas palabras,además del procesamiento de paralelismo para mejorar los tiempos de ejecución seagrega la ganancia conceptual, al poder resolver los problemas con nuevos métodosde resolución hasta ahora imposibles de ejecutarse en máquinas secuenciales.Así, la computación paralela está jugando un papel fundamental en el avance de todaslas ciencias, abriendo las puertas para explotar, más allá de las fronteras ya conocidas,impresionantes poderes de cálculo que permiten modelos más realistas (pasar de lasegunda a la tercer dimensión, etc.). A pesar de que del área de computación paralela sehabla mucho, en realidad es poco lo que se conoce. Quizás el mayor problema encomputación paralela y distribuida es que no son ideas fáciles para entender eimplementar. Existen diferentes enfoques para aplicar paralelismo. Incluso, para ciertasaplicaciones algunos enfoques pueden ser contraproducentes. Además, existen variostipos de arquitecturas, modelos de programación, lenguajes y compiladores, compitiendopor conquistar el mercado. Por otro lado, actualmente los precios baratos de los PC, consu incremento en poder de cálculo, los hacen un formidable competidor contra losemergentes computadores paralelos. También las estaciones de trabajo, las cuales ofrecenamigables y poderosas interfaces, son otras fuertes competidoras.Hay muchas áreas de aplicación donde el poder de cálculo de una computadorasimple es insuficiente para obtener los resultados deseados. Las computadoras paralelas ydistribuidas pueden producir resultados más rápidos. Por ejemplo, en algunas áreas decálculo científico, el tiempo estimado de computación para obtener resultadosinteresantes usando un computador simple, podría ser tan largo que excedería el tiempoesperado en que el mismo puede fallar. O peor aun, en el área industrial una simulaciónque tome algunas semanas para alcanzar resultados, es usualmente inaceptable enambientes de diseño, en los cuales los tiempos con los que cuenta el diseñador son cortos.Además, hay ciertos problemas que tienen fechas límites especificas para calcularse (porejemplo, si el programa de predicción del tiempo para el día de mañana dura dos díasperdería el sentido ejecutarlo). Un punto inicial de arranque sería conocer qué áreas deaplicación podrían beneficiarse al usar paralelismo. Indudablemente, el primer gruposerían aquellas áreas donde el paralelismo es aparente, aunque no se pueda explotar enmáquinas secuenciales.